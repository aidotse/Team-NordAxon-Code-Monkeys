{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will facilitate the end-to-end usage of the NordAxon Code Monkeys solution to the Adipocyte Imaging Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We assume that you have a folder, called \"raw data dir\" in this notebook, that contains raw input brightfield images, and that you want to predict nuclei, adipocytes and lipid droplets for these images. In this notebook, the end-to-end pipeline for doing this will be described.\n",
    "\n",
    "### 1. The first step is to prepare the raw data. \n",
    "The image below shows how the pipeline looks for this. All code for this part can be found under src/prepare_training_data.py. Depending on what your file structure looks like, you will call different commands here.\n",
    "\n",
    "What will happen in this step is that you provide two filepaths, one to the raw images, and one \"middle step\" where you want to store the modified input images that we will predict on. These two paths will be used in the \"prepare_inference_dataset.py\" file, where the following will happen:\n",
    "\n",
    "<img src=\"./flows.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "This means that, after this script, you will have a folder where the raw input data is restructured to fit our prediction pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We start by defining our input and output directories for this!\n",
    " Point the input_dir to your raw data dir, and your output_dir to where you want to store the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here:\n",
    "raw_data_dir = '../data/03_training_data/normalized_bias/train/input/'\n",
    "prediction_data_dir = \"../data/04_generated_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If your file structure corresponds to the following (target and mask folders are optional):\n",
    "\n",
    "- Data dir\n",
    "    - input\n",
    "        - 20x\n",
    "            - img1\n",
    "            - img2\n",
    "            - ...\n",
    "        - 40x\n",
    "            - ...\n",
    "        - 60x\n",
    "            - ...\n",
    "    - target\n",
    "        - 20x\n",
    "        - 40x\n",
    "        - 60x\n",
    "    - masks\n",
    "        - 20x\n",
    "        - 40x\n",
    "        - 60x\n",
    "        \n",
    "#### you will run the cell directly below this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing all kinds of advanced stuff..\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  2.00it/s]\n",
      "hello world\n",
      "../data/03_training_data/normalized_bias/train/input/20x_images\n",
      "../data/04_generated_images/20x_images\n"
     ]
    }
   ],
   "source": [
    "!python print_hello.py --input_dir $raw_data_dir --output_dir $prediction_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And if your file structure corresponds to this format (target and mask folders still optional):\n",
    "\n",
    "- Data dir\n",
    "    - 20x\n",
    "        - Input\n",
    "            - img1\n",
    "            - img2\n",
    "            - ...\n",
    "        - Target\n",
    "            - ...\n",
    "        - Masks\n",
    "            - ...\n",
    "    - 40x\n",
    "        - Input\n",
    "        - Target\n",
    "        - Masks\n",
    "    - 60x\n",
    "        - Input\n",
    "        - Target\n",
    "        - Masks\n",
    "    \n",
    "#### You will run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing all kinds of advanced stuff..\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  2.00it/s]\n",
      "hello world\n",
      "../data/03_training_data/normalized_bias/train/input/20x_images\n",
      "../data/04_generated_images/20x_images\n"
     ]
    }
   ],
   "source": [
    "!python print_hello.py --input_dir $raw_data_dir --output_dir $prediction_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The second step is to predict for each target\n",
    "When predicting, the pipeline differs slightly depending on the target image that we want to predict. This is because we have chosen to use masks for the A01 target (nuclei).\n",
    "In the image below, the flow is described for prediction. In the code, predictions.py will be called one time for each magnification.\n",
    "\n",
    "<img src=\"./flows2.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "What this flow chart shows is that the masks are only loaded if the target is the nuclei, i.e. A01.\n",
    "\n",
    "Now, we need to define an output path to where we want our predicted images to be! And, we want to define the path to the model weights that we want to use. Fortunately, we have done this for you, but you are free to change this if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here:\n",
    "predictions_dir = \"../data/04_generated_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting images for target A1...\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  2.00it/s]\n",
      "hello world\n",
      "../data/04_generated_images/\n",
      "../data/04_generated_images/\n",
      "../../data/05_saved_models/A1_g_best.pth\n",
      "Predicting images for target A2...\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  2.00it/s]\n",
      "hello world\n",
      "../data/04_generated_images/\n",
      "../data/04_generated_images/\n",
      "../../data/05_saved_models/A2_g_best.pth\n",
      "Predicting images for target A3...\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  2.00it/s]\n",
      "hello world\n",
      "../data/04_generated_images/\n",
      "../data/04_generated_images/\n",
      "../../data/05_saved_models/A3_g_best.pth\n"
     ]
    }
   ],
   "source": [
    "model_weights_path_A1 = \"../../data/05_saved_models/A1_g_best.pth\"\n",
    "model_weights_path_A2 = \"../../data/05_saved_models/A2_g_best.pth\"\n",
    "model_weights_path_A3 = \"../../data/05_saved_models/A3_g_best.pth\"\n",
    "\n",
    "!python print_hello_2.py --mask --target A1 --input_dir $prediction_data_dir  --output_dir $predictions_dir --weights $model_weights_path_A1\n",
    "\n",
    "!python print_hello_2.py --target A2 --input_dir $prediction_data_dir  --output_dir $predictions_dir --weights $model_weights_path_A2\n",
    "\n",
    "!python print_hello_2.py --target A3 --input_dir $prediction_data_dir  --output_dir $predictions_dir --weights $model_weights_path_A3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
