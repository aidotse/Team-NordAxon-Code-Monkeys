{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will facilitate the end-to-end usage of the NordAxon Code Monkeys solution to the Adipocyte Imaging Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We assume that you have a folder, called \"raw data dir\" in this notebook, that contains raw input brightfield images, and that you want to predict nuclei, adipocytes and lipid droplets for these images. In this notebook, the end-to-end pipeline for doing this will be described.\n",
    "\n",
    "### 1. The first step is to prepare the raw data. \n",
    "The image below shows how the pipeline looks for this. All code for this part can be found under src/prepare_training_data.py. Depending on what your file structure looks like, you will call different commands here.\n",
    "\n",
    "What will happen in this step is that you provide two filepaths, one to the raw images, and one \"middle step\" where you want to store the modified input images that we will predict on. These two paths will be used in the \"prepare_inference_dataset.py\" file, where the following will happen:\n",
    "\n",
    "<img src=\"./flows.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "This means that, after this script, you will have a folder where the raw input data is restructured to fit our prediction pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We start by defining our input and output directories for this!\n",
    " Point the input_dir to your raw data dir, and your output_dir to where you want to store the training data (Note: IMPORTANT that the raw data dir contains the directory names **20x_images, 40x_images, 60x_images** see below!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, copy inference data to '../data/01_raw/' directory\n",
    "path_to_your_data = \n",
    "\n",
    "mkdir '../data/01_raw/adipocyte_inference_data'\n",
    "!cp -r $path_to_your_data '../data/01_raw/adipocyte_inference_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here:\n",
    "raw_data_dir = '../data/01_raw/adipocyte_inference_data'\n",
    "prediction_data_dir = \"../data/07_inference_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If your file structure corresponds to the following (target and mask folders are optional):\n",
    "\n",
    "- input_dir\n",
    "    - input\n",
    "        - 20x_images\n",
    "            - img1\n",
    "            - img2\n",
    "            - ...\n",
    "        - 40x_images\n",
    "            - ...\n",
    "        - 60x_images\n",
    "            - ...\n",
    "    - target\n",
    "        - 20x_images\n",
    "        - 40x_images\n",
    "        - 60x_images\n",
    "\n",
    "or\n",
    "\n",
    "- input_dir\n",
    "    - 20x_images\n",
    "        - input\n",
    "            - img1\n",
    "            - img2\n",
    "            - ...\n",
    "        - target\n",
    "    - 40x_images\n",
    "        - ...\n",
    "    - 60x_images\n",
    "        - ...\n",
    "        \n",
    "or\n",
    "\n",
    "- input_dir\n",
    "    - 20x_images\n",
    "        - img1\n",
    "        - img2\n",
    "        - ...\n",
    "    - 40x_images\n",
    "        - ...\n",
    "    - 60x_images\n",
    "        - ...\n",
    "        \n",
    "#### you will run the cell directly below this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(input_dir='../data/01_raw/', output_dir='../data/07_inference_data/')\n",
      "Found 2080 .tif images in total\n",
      "100%|███████████████████████████████████████| 2080/2080 [02:52<00:00, 12.07it/s]\n"
     ]
    }
   ],
   "source": [
    "!python ../src/prepare_inference_data.py --input-dir $raw_data_dir --output-dir $prediction_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The second step is to predict for each target\n",
    "When predicting, the pipeline differs slightly depending on the target image that we want to predict. This is because we have chosen to use masks for the A01 target (nuclei).\n",
    "In the image below, the flow is described for prediction. In the code, predictions.py will be called one time for each magnification.\n",
    "\n",
    "<img src=\"./flows2.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "What this flow chart shows is that the masks are only loaded if the target is the nuclei, i.e. A01.\n",
    "\n",
    "Now, we need to define an output path to where we want our predicted images to be! And, we want to define the path to the model weights that we want to use. Fortunately, we have done this for you, but you are free to change this if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path_A1_mask = \"../data/05_saved_models/normalized_bias/A1_segmentation_model_2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]\r",
      "0it [00:00, ?it/s]\r\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"../data/07_inference_data/input/20x_images\"\n",
    "output_dir = \"../data/07_inference_data/masks/20x_images\"\n",
    "python predict_segmentation.py --input-dir $input_dir --output-dir $output_dir --weights_path $weights_path_A1_mask\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/40x_images\"\n",
    "output_dir = \"../data/07_inference_data/masks/40x_images\"\n",
    "python predict_segmentation.py --input-dir $input_dir --output-dir $output_dir --weights_path $weights_path_A1_mask\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/60x_images\"\n",
    "output_dir = \"../data/07_inference_data/masks/60x_images\"\n",
    "python predict_segmentation.py --input-dir $input_dir --output-dir $output_dir --weights_path $weights_path_A1_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting images for target A1...\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  2.00it/s]\n",
      "hello world\n",
      "../data/04_generated_images/\n",
      "../data/04_generated_images/\n",
      "../../data/05_saved_models/A1_g_best.pth\n",
      "Predicting images for target A2...\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  2.00it/s]\n",
      "hello world\n",
      "../data/04_generated_images/\n",
      "../data/04_generated_images/\n",
      "../../data/05_saved_models/A2_g_best.pth\n",
      "Predicting images for target A3...\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  2.00it/s]\n",
      "hello world\n",
      "../data/04_generated_images/\n",
      "../data/04_generated_images/\n",
      "../../data/05_saved_models/A3_g_best.pth\n"
     ]
    }
   ],
   "source": [
    "weights_path_A1 = \"../../data/05_saved_models/normalized_bias/A1_g_best.pth\"\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/20x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/20x_images\"\n",
    "!python ../src/predict.py --target A1 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A1 --mag 20x --match-histogram\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/40x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/40x_images\"\n",
    "!python ../src/predict.py --target A1 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A1 --mag 40x --match-histogram\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/60x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/60x_images\"\n",
    "!python ../src/predict.py --target A1 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A1 --mag 60x --match-histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path_A2 = \"../../data/05_saved_models/normalized_bias/A2_g_best.pth\"\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/20x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/20x_images\"\n",
    "!python ../src/predict.py --target A2 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A2 --mag 20x --match-histogram\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/40x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/40x_images\"\n",
    "!python ../src/predict.py --target A2 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A2 --mag 40x --match-histogram\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/60x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/60x_images\"\n",
    "!python ../src/predict.py --target A2 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A2 --mag 60x --match-histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path_A3 = \"../../data/05_saved_models/normalized_bias/A3_g_best.pth\"\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/20x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/20x_images\"\n",
    "!python ../src/predict.py --target A3 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A3 --mag 20x --match-histogram\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/40x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/40x_images\"\n",
    "!python ../src/predict.py --target A3 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A3 --mag 40x --match-histogram\n",
    "\n",
    "input_dir = \"../data/07_inference_data/input/60x_images\"\n",
    "output_dir = \"../data/04_generated_images/inference_results/60x_images\"\n",
    "!python ../src/predict.py --target A3 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A3 --mag 60x --match-histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of working pipeline\n",
    "\"\"\"\n",
    "for mag in [\"20x\", \"40x\", \"60x\"]:\n",
    "    input_dir = f\"../../data/03_training_data/normalized_bias/valid/input/{mag}_images\"\n",
    "    output_dir = f\"../../data/04_generated_images/valid_inference_results/{mag}_images\"\n",
    "    !python ../../src/predict.py --target A01 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A1 --mag {mag} --match-histogram\n",
    "\n",
    "                       \n",
    "for mag in [\"20x\", \"40x\", \"60x\"]:\n",
    "    input_dir = f\"../../data/03_training_data/normalized_bias/valid/input/{mag}_images\"\n",
    "    output_dir = f\"../../data/04_generated_images/valid_inference_results/{mag}_images\"\n",
    "    !python ../../src/predict.py --target A02 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A2 --mag {mag} --match-histogram\n",
    "                       \n",
    "\n",
    "for mag in [\"20x\", \"40x\", \"60x\"]:\n",
    "    input_dir = f\"../../data/03_training_data/normalized_bias/valid/input/{mag}_images\"\n",
    "    output_dir = f\"../../data/04_generated_images/valid_inference_results/{mag}_images\"\n",
    "    !python ../../src/predict.py --target A03 --input-dir $input_dir  --output-dir $output_dir --weights $weights_path_A3 --mag {mag} --match-histogram\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
